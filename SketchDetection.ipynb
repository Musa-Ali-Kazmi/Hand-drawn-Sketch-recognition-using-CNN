{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zqBxLTmgTj9zPkFsS_lMJ7gobaGinWec",
      "authorship_tag": "ABX9TyM7Hr/GNk0OEs1O4oqtPKmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Musa-Ali-Kazmi/Hand-drawn-Sketch-recognition-using-CNN/blob/main/SketchDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install unrar"
      ],
      "metadata": {
        "id": "OG7zVNgKde5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f192bc-5bab-473b-c598-c5dc9bde298b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/drive/MyDrive/DL-Assignment2/Train.rar /content/drive/MyDrive/DL-Assignment2\n"
      ],
      "metadata": {
        "id": "DBf7gco6dmjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/drive/MyDrive/DL-Assignment2/Validation.rar /content/drive/MyDrive/DL-Assignment2"
      ],
      "metadata": {
        "id": "JHCMplXgeOCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "Mozk3Ou3e5dk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file containing image filenames and labels\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/DL-Assignment2/Train.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/DL-Assignment2/Validation.csv')\n",
        "\n",
        "# Define ImageDataGenerator for data augmentation and normalization\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0,1]\n",
        "    rotation_range=20,  # Random rotation up to 20 degrees\n",
        "    width_shift_range=0.2,  # Random shift width up to 20% of the image width\n",
        "    height_shift_range=0.2,  # Random shift height up to 20% of the image height\n",
        "    shear_range=0.2,  # Shear intensity (shear angle in counter-clockwise direction in degrees)\n",
        "    zoom_range=0.2,  # Random zoom up to 20%\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        ")\n",
        "\n",
        "train_df['Image'] = train_df['Image'].astype(str)  # Convert values in 'Image' column to strings\n",
        "val_df['Image'] = val_df['Image'].astype(str)  # Convert values in 'Image' column to strings\n",
        "\n",
        "train_df['Label'] = train_df['Label'].astype(str)  # Convert values in 'Label' column to strings\n",
        "val_df['Label'] = val_df['Label'].astype(str)  # Convert values in 'Label' column to strings\n",
        "\n",
        "# Assuming 'x_column_name' is the name of the column containing the filenames\n",
        "train_df['Image'] = train_df['Image'].apply(lambda x: str(x) + '.png')\n",
        "val_df['Image'] = val_df['Image'].apply(lambda x: str(x) + '.png')\n",
        "\n",
        "\n",
        "# Flow images from the \"Train\" folder using the ImageDataGenerator and dataframe\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='/content/drive/MyDrive/DL-Assignment2/Train',  # Path to the directory containing the images\n",
        "    x_col=\"Image\",  # Column containing the image filenames\n",
        "    y_col=\"Label\",  # Column containing the image labels\n",
        "    target_size=(224, 224),  # Resize images to 224x224\n",
        "    batch_size=64,  # Batch size\n",
        "    class_mode='categorical'  # Type of label encoding\n",
        "  )\n",
        "\n",
        "# Flow images from the \"Train\" folder using the ImageDataGenerator and dataframe\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory='/content/drive/MyDrive/DL-Assignment2/Validation',  # Path to the directory containing the images\n",
        "    x_col=\"Image\",  # Column containing the image filenames\n",
        "    y_col=\"Label\",  # Column containing the image labels\n",
        "    target_size=(224, 224),  # Resize images to 224x224\n",
        "    batch_size=64,  # Batch size\n",
        "    class_mode='categorical'  # Type of label encoding\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTxi8zRGj19o",
        "outputId": "1f178106-0351-4254-8249-664508c0f114"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 validated image filenames belonging to 250 classes.\n",
            "Found 5000 validated image filenames belonging to 250 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet-50 pre-trained on ImageNet without the top classification layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkyhfY8Kf2rX",
        "outputId": "1a314c91-4fe7-4d69-990e-36ad01e79c8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create your model on top of ResNet50\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(250, activation='softmax')  # Example output classes, adjust as needed\n",
        "])"
      ],
      "metadata": {
        "id": "F94i3AByf6th"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "mJkK2P_ggquM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a230c2a9-9a25-4dfc-debc-bf9193b5c721"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, None, None, 2048   23587712  \n",
            "                             )                                   \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 250)               64250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24176506 (92.23 MB)\n",
            "Trainable params: 588794 (2.25 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the train_generator\n",
        "history = model.fit(\n",
        "                              train_generator,\n",
        "                              steps_per_epoch=len(train_generator),\n",
        "                              epochs=10,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=len(val_generator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZGhk2N0vfw7",
        "outputId": "282d35f7-b6a5-4ac6-9deb-d516cc88d3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 5701s 36s/step - loss: 5.5017 - accuracy: 0.0058 - val_loss: 5.4606 - val_accuracy: 0.0096\n",
            "Epoch 2/10\n",
            " 38/157 [======>.......................] - ETA: 2:39 - loss: 5.4482 - accuracy: 0.0049"
          ]
        }
      ]
    }
  ]
}